{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFHv-dOPdYri"
   },
   "source": [
    "# Motivation\n",
    "\n",
    "This notebook will be used to document and test my idea of using structure vectors as learned descriptors that are then passed through a shallow neural network. This idea was motivated by two main facts:\n",
    "\n",
    "1) I believe that my current models are being limited by the fact that they lack the \"mixing\" abilities of NN-style potentials. In NNPs, each descriptor component is a sum over the local environment of an atom; those components are then mixed with each other by the NN. In my models this mixing is impossible because  my model is essentially a single-layer network.\n",
    "\n",
    "2) None of the major MLIPs have learned descriptors, at least as far as I can tell. Based on my understanding, NNP (and its variants), GAP, MTP, and SNAP all define their descriptors using expansions with various basis functions, with the difference between each model being which basis functions they use and which distance kernels they use. SchNet would be an example of a model with learned descriptors (since they use CNN-like filters), but reportedly suffers from significant speed issues.\n",
    "\n",
    "# Open questions\n",
    "* How are eng and force SVs used at the same time?\n",
    "\n",
    "# TO DO\n",
    "* Normalize data\n",
    "* Try fitting SVs first\n",
    "* Try using CMA-ES\n",
    "* Try smaller SVs, but more of them\n",
    "* **Pin ends of radial functions**\n",
    "\n",
    "\n",
    "# Theory notes\n",
    "\n",
    "## Why are my SVTrees just single-layer networks?\n",
    "Though this comment had been made by a reviewer on my s-MEAM work, I hadn't fully understood it until now. I came to this realization when I spent more time understanding how the descriptors were built for NNPs ([the ANI paper](https://pubs.rsc.org/en/content/articlepdf/2017/sc/c6sc05720a) and [its supplementary information](http://www.rsc.org/suppdata/c6/sc/c6sc05720a/c6sc05720a1.pdf) were particularly useful). The individual components of the NNP descriptors are constructed by choosing a basis function (e.g. a shifted gaussian) and summing its values over pair distances or angles within a single atomic environment. The full descriptors are then the concatenation of multiple of these components for each \"bond type\". These descriptors are then fed through a neural network (using a different network for each \"host atom\" type, which is exactly what I do). In the limit where the NN has only a single layer, each component would is simply summed, which is exactly the case with my trees. There are some minor technical differences, like the fact that my trees can essentially have different activation functions for each node (by wrapping individual SVs in different embedding functions) and that my SVs are learnable and will most likely be more complex than any single basis function (e.g. it could take up to $k$ RBFs to approximate a spline with $k$ knots), but the statement is still essentially true: **my trees are single-layer NN potentials.**\n",
    "\n",
    "## What is the idea that I'm proposing?\n",
    "In order to improve the accuracy/flexibility of my models, my proposition is to use the outputs of multiple SVs as the inputs to a shallow neural network. For example, I could define an atomic fingerprint for atom $i$ of element type $X$ as the length-2 vector $$\\vec{G}^X_i(S) = \\langle \\rho(S)_i \\text{, } \\text{FFG}(S)_i \\rangle $$ where $\\rho(S)_i$ and $\\text{FFG}(S)_i$ are the 2- and 3-body structure vectors of the local environment around atom $i$. The network would then have an input dimension of 2 (since 2 SVs were used), and an output dimension of 1 (for the atomic energy). This would allow the type of \"component mixing\" that I believe is responsible for the high accuracy of NNP-like models. The number of 2- and 3-body SVs to use would be a hyper-parameter choice, but based on past experience I think 2-3 of each would prove to be sufficient.\n",
    "\n",
    "Note that although this use of SVs is quite different from what we are used to thinking of them as, it is very similar to how descriptors for NNP-like models are currently generated. The evaluation of an SV no longer represents an atomic energy -- now it represents something like an atomic density. Instead of using a specific number of manually-constructed basis functions to construct the components of the descriptors, as is the case with NNPs, a single SV can be used. For example, instead of using 7 different gaussian basis functions shifted by 7 different atomic distances, I could use a single SV with 7 knots. The idea here is that by fitting a spline as the embedding function we're able to learn the descriptors instead of constructing them manually.\n",
    "\n",
    "## Would this actually be useful?\n",
    "\n",
    "TLDR: I don't know, but it seems worth exploring! It would be faster than NNPs, it might be more interpretable, it would probably be at least as accurate, and we already have fast fitting code for it.\n",
    "\n",
    "* **Speed:** MLIPs notoriously have the problem that constructing the descriptors is extremely expensive. For example, in the AL_Al ANI network I'm pretty sure that they're using 32 radial functions and 64 angular functions. This would make it around 60x slower than a single-element s-MEAM -- this approximation appears to be a bit high though, since the NNPs from the mlearn work only seem to be ~10x slower. But still, that's not a small number. I would also plan to use much fewer descriptors (2-3 each of radial/angular?), which would make the NN itself much smaller; this speed is probably negligible though.\n",
    "\n",
    "* **Interpretability:** it seems possible, but in no way guaranteed, that an SV would be more interpretable than the descriptors used for a NNP. In the ANI supplementary material they compare the descriptors for two structures by simply plotting all of the components. While this would conceivably still be somewhat interpretable, it would require a lot of back-and-forth checking of what each component represents. Plotting the SVs themselves wouldn't give the descriptors, but it would give insight into how the embedding of local environments is being done. This is theoretically useful, but from my experience I think it's likely that only a few of the splines would be interpretable, while others might be too \"wiggly\" to understand. But still, maybe better than looking at the NNP embeddings? Also, you'd be able to enforce certain physical behaviors by pinning knots (e.g. forcing convergence to 0 energy at far distances).\n",
    "\n",
    "* **Accuracy:** I think this is the most difficult attribute to appraise. I don't see any obvious reason why a learned descriptor would be any more/less accurate than a manually-constructed descriptor using a large number of basis functions. Furthermore, I still haven't figured out how to incorporate long-range interactions into an SV. However, the use of the NN to mix the outputs of multiple SVs would almost certainly improve the accuracy of the tree-based models.\n",
    "\n",
    "* **Fitting:** we would be able to leverage all of the advantages of fitting with SVs that we've already been using.\n",
    "\n",
    "## Are you sure that other models aren't learning their descriptors?\n",
    "No, but I'm pretty sure?\n",
    "\n",
    "* **NNP:** as I said before, NNPs and their variants define their descriptor components by choosing a certain number of shifted gaussians, then concatenating the sums of those gaussians over local environments. The learning is only on the NN weights and biases. While the descriptors could technically be considered \"learnable\" using hyper-parameter tuning methods, this is rarely (if ever) done.\n",
    "\n",
    "* **GAP:** the SOAP descriptors used by GAP are kernel functions that output distance metrics that operate on atomic densities that have been written as Bessel function expansions. Yes, there's much more complicated math going on there, but I think this is still essentially true. These kernel functions produce distance metrics that are used in gaussian process regression. The only learning that is done is during the GPR.\n",
    "\n",
    "* **MTP:** MTPs are just doing linear regression on contracted moment tensors that were constructed using basis functions that are expansions of \"moment polynomials\". The strength of this method is in the fact that MTP can use increasingly many moment tensor. Their paper says that the basis functions can theoretically span all permutation- and rotation- invariant polynomials. This method seems the most competetive with my idea; by expressing the energy of an atom as a linear combination of these basis functions, it seems that while it isn't necessarily learning descriptors, the descriptors that it's using are complex enough to do nearly anything. I need to understand MTP a bit better, I think; what are the drawbacks of MTP, if any?\n",
    "\n",
    "* **SNAP:** Nope; I think this is like MTP, but with worse descriptors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wk49GST1dYro"
   },
   "source": [
    "# Implementation\n",
    "\n",
    "## Technical notes\n",
    "* If I store the parameter sets, including those dotted with the SVs, as PyTorch tensors with `requires_grad=True`, I think they can handle the back-propogation on their own.\n",
    "* This formalism can use the versions of the force SVs that are contracted along the neighbor dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4THGdN1dYrp"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzgOlF8AdYrq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import glob\n",
    "import h5py\n",
    "import random\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Al64IO5DdYrr"
   },
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "oS_b_UnfdYrs"
   },
   "outputs": [],
   "source": [
    "class SVDataset(Dataset):\n",
    "    def __init__(self, path, elements, svNames, refStruct):\n",
    "        super(SVDataset, self).__init__()\n",
    "        \n",
    "        self.refStruct = refStruct\n",
    "        \n",
    "        with h5py.File(path, 'r') as db:\n",
    "            \n",
    "            self.structNames = sorted(list(db.keys()))\n",
    "            self.refStruct = self.structNames[0]\n",
    "            self.refIdx = self.structNames.index(self.refStruct)\n",
    "            \n",
    "            self.elements = elements\n",
    "            self.svNames = svNames\n",
    "\n",
    "            self.all_true_eng = []\n",
    "            self.all_true_fcs = []\n",
    "            self.natoms = []\n",
    "\n",
    "            self.svs = {}\n",
    "            for svn in svNames:\n",
    "                self.svs[svn] = {}\n",
    "                for el in elements:\n",
    "                    self.svs[svn][el] = {}\n",
    "                    self.svs[svn][el]['energy'] = []\n",
    "                    self.svs[svn][el]['forces'] = []\n",
    "\n",
    "            for i, k in enumerate(self.structNames):\n",
    "                print(i, k)\n",
    "                self.all_true_eng.append(db[k].attrs['energy'])\n",
    "                self.all_true_fcs.append(db[k].attrs['forces'].ravel())\n",
    "                self.natoms.append(db[k].attrs['natoms'])\n",
    "\n",
    "                for svn in svNames:\n",
    "                    for el in elements:\n",
    "                        self.svs[svn][el]['energy'].append(db[k][svn][el]['energy'][()])\n",
    "                        self.svs[svn][el]['forces'].append(db[k][svn][el]['forces'][()])\n",
    "\n",
    "            self._len = len(self.all_true_eng)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        svs_eng = {\n",
    "            'rho_A': rho_svs_e,\n",
    "            'ffg_AA': ffg_svs_e\n",
    "        }\n",
    "\n",
    "        svs_fcs = {\n",
    "            'rho_A': rho_svs_f,\n",
    "            'ffg_AA': ffg_svs_f\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'svs_e': {svn: {el: self.svs[svn][el]['energy'][idx] for el in self.elements} for svn in self.svNames},\n",
    "            'svs_f': {svn: {el: self.svs[svn][el]['forces'][idx] for el in self.elements} for svn in self.svNames},\n",
    "            'natoms': self.natoms[idx],\n",
    "            'energy': self.all_true_eng[idx],\n",
    "            'forces': self.all_true_fcs[idx],\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NzyeArldYrt"
   },
   "source": [
    "## Embedder and Model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "ZnTPpbDKdYrt"
   },
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self, embeddings, device):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embeddings (dict):\n",
    "                Key = embedder name\n",
    "                Value = 3-tuple\n",
    "                    First: list of dimensions of embedder components\n",
    "                    Second: component orders for building outer products\n",
    "                    Third: number of duplicates to use\n",
    "                \n",
    "                Example:\n",
    "                    embeddings = {\n",
    "                        'rho_A': ([9], [0], 2),  # Builds 2 Rho\n",
    "                        'ffg_AA': ([9, 9], [0, 0, 1], 3)  # Builds 3 F*F*G\n",
    "                    }\n",
    "        \"\"\"\n",
    "        super(Embedder, self).__init__()\n",
    "        \n",
    "        self.embeddings = embeddings\n",
    "        self._embedding_order = sorted(list(self.embeddings.keys()))\n",
    "        \n",
    "        # Register embedding parameters so that they get learned\n",
    "        input_dim = 0\n",
    "        for key, (size_list, build_order, duplicates) in self.embeddings.items():\n",
    "            for dup in range(duplicates):\n",
    "                # Build parameter vectors\n",
    "#                 params = [nn.Parameter(torch.rand(nk)) for nk in size_list]\n",
    "                params = []\n",
    "                for idx, nk in enumerate(size_list):\n",
    "#                     if ('rho' in key) or (('ffg' in key) and (idx != len(self.embeddings[key][0])-1)):\n",
    "                    if False:\n",
    "                        # Radial splines\n",
    "                        params.append(nn.Parameter(torch.rand(nk-2)))\n",
    "                    else:\n",
    "                        params.append(nn.Parameter(torch.rand(nk)))\n",
    "                        \n",
    "                input_dim += 1\n",
    "\n",
    "                # Record each parameter set (with unique key) for autograd\n",
    "                for i, pset in enumerate(params):\n",
    "                    bigKey = key + '_' + str(dup) + '_' + str(i)\n",
    "                    setattr(self, bigKey, pset)\n",
    "    \n",
    "        # Used for resuming training plots\n",
    "        self.steps = 0\n",
    "        \n",
    "        self._zero = torch.zeros(1).view((1,)).to(device)\n",
    "        self._device = device\n",
    "        \n",
    "    def _fill(self, key, dup, idx):\n",
    "        name = key + '_' + str(dup) + '_' + str(idx)\n",
    "        pset = getattr(self, name)\n",
    "\n",
    "#         if ('rho' in key) or (('ffg' in key) and (idx != len(self.embeddings[key][0])-1)):\n",
    "        if False:\n",
    "            # Radial splines need to have pinned RHS knot and derivative\n",
    "            tmp = torch.cat(\n",
    "                [pset[:-1],\n",
    "                 self._zero,\n",
    "                 pset[-1].view((1,)),\n",
    "                 self._zero]\n",
    "            ).to(self._device)\n",
    "        else:\n",
    "            tmp = pset\n",
    "        \n",
    "        return tmp, name\n",
    "        \n",
    "        \n",
    "    def _conv(self, key, dup):\n",
    "        \"\"\"\n",
    "        Helper function to compute the outer products of parameter sets\n",
    "        \n",
    "        Args:\n",
    "            key (str):\n",
    "                Name of embedder to build\n",
    "            dup (int):\n",
    "                Which duplicate to work with\n",
    "        \"\"\"\n",
    "\n",
    "        build_order = self.embeddings[key][1]\n",
    "        \n",
    "        cart = None\n",
    "        for idx in build_order:\n",
    "            pset, _ = self._fill(key, dup, idx)\n",
    "\n",
    "            if cart is None:\n",
    "                cart = pset\n",
    "            else:\n",
    "                cart = torch.outer(cart, pset)\n",
    "                cart = cart.view(cart.shape[0]*pset.shape[0])\n",
    "        \n",
    "        return cart.to(device)\n",
    "    \n",
    "    def embed(self, svs_fcs):#, svs_fcs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            svs_eng (dict):\n",
    "                Key = embedder name (must match `embeddings` keys from __init__)\n",
    "                Value = tensor of shape (N_tot, nk_cart), where N_tot is the\n",
    "                    total number of atomic environments and nk_cart is the size\n",
    "                    of the structure vector for the given embedder.\n",
    "                    \n",
    "            svs_fcs (dict):\n",
    "                Same as `svs_eng`, but the values have the shape (N_tot, 3, nk_cart)\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # Build the atomic embeddings\n",
    "#         descriptors_eng = []\n",
    "        descriptors_fcs = []\n",
    "        for k in self._embedding_order:\n",
    "            for dup in range(self.embeddings[k][2]):\n",
    "                cart = self._conv(k, dup)\n",
    "#                 descriptors_eng.append(torch.matmul(svs_eng[k], cart).unsqueeze(-1))\n",
    "                descriptors_fcs.append(torch.matmul(svs_fcs[k], cart).unsqueeze(-1))\n",
    "            \n",
    "#         descriptors_eng = torch.cat(descriptors_eng, dim=1)\n",
    "        descriptors_fcs = torch.cat(descriptors_fcs, dim=2)\n",
    "        \n",
    "        descriptors_fcs = descriptors_fcs.view((descriptors_fcs.shape[0]*3, descriptors_fcs.shape[-1]))\n",
    "        \n",
    "        return descriptors_fcs#, descriptors_fcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "N_DJg4JUdYrv"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1=3, hidden_dim2=3):\n",
    "\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.linear2 = nn.Linear(hidden_dim1, hidden_dim1)\n",
    "        self.linear3 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.linear4 = nn.Linear(hidden_dim2, 1)\n",
    "        \n",
    "        self.bnorm1 = nn.BatchNorm1d(num_features=hidden_dim1)\n",
    "        self.splus  = nn.Softplus()\n",
    "        self.celu   = nn.CELU()\n",
    "        \n",
    "        # Used for resuming training plots\n",
    "        self.steps = 0\n",
    "        \n",
    "    def _forward(self, x):\n",
    "        \"\"\"\n",
    "        Helper function for passing the embeddings through the network\n",
    "        \"\"\"\n",
    "        out = self.linear1(x)\n",
    "        out = self.celu(out)\n",
    "        out = self.bnorm1(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.celu(out)\n",
    "        out = self.linear3(out)\n",
    "        out = self.celu(out)\n",
    "        out = self.linear4(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "#     def forward(self, descriptors_eng, descriptors_fcs, splits):\n",
    "    def forward(self, descriptors_fcs, splits):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            splits (list):\n",
    "                N_s integers corresponding to the number of atoms in each of the N_s\n",
    "                structures being evaluated. Used for splitting intermediate results.\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        # Evaluate the model\n",
    "#         atomic_eng = self._forward(descriptors_eng)\n",
    "#         eng = torch.cat([eatom.sum().view(1)/n for n, eatom in zip(splits, torch.split(atomic_eng, splits))])\n",
    "        \n",
    "        fcs = self._forward(descriptors_fcs).squeeze()\n",
    "\n",
    "        return fcs\n",
    "#         return eng#, fcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOrYHQCRdYrx"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpKn3ihcdYrx",
    "outputId": "86041681-3123-4979-b66a-aaa7428f7673"
   },
   "outputs": [],
   "source": [
    "path = os.path.join('/home', 'vita', 'AL_Al-7knots-full-allsums.hdf5')\n",
    "dataset = SVDataset(path, ['Al'], ['rho_A', 'ffg_AA'], 'AL-step_14-data-003.001.012.000.000.005.h5-0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fcs = np.array([np.max(abs(f)) for f in dataset.all_true_fcs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(max_fcs, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badIndices = np.where(max_fcs > 30)[0]\n",
    "badIndices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9Id7JYYdYry"
   },
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uvRZMLGy7fuS",
    "outputId": "3563abb0-0b66-4699-a277-3b1ec4d4c912"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VALZ5ORKdYrz"
   },
   "outputs": [],
   "source": [
    "nrho = 4\n",
    "nffg = 8\n",
    "hidden_dim1 = 128\n",
    "hidden_dim2 = 32\n",
    "\n",
    "embeddings = {\n",
    "    'rho_A': ([9], [0], nrho),\n",
    "    'ffg_AA': ([9, 9], [0, 0, 1], nffg)\n",
    "}\n",
    "\n",
    "embedder = Embedder(embeddings, device)\n",
    "model = Model(nrho+nffg, hidden_dim1=hidden_dim1, hidden_dim2=hidden_dim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13l4d5AbdYr1"
   },
   "outputs": [],
   "source": [
    "baseName = 'AL_Al'\n",
    "savePath = 'runs/{}_r_{}_f_{}_h1_{}_h2_{}_f_6352_unpin'.format(baseName, nrho, nffg, hidden_dim1, hidden_dim2)\n",
    "writer = SummaryWriter(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda s: int(os.path.split(s)[-1].split('.')[0])\n",
    "sorted(glob.glob(os.path.join(savePath, '*.model')), key=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 910\n",
    "embedder.load_state_dict(torch.load(os.path.join(savePath, '{}.embedder'.format(ii))))\n",
    "embedder.eval()\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(savePath, '{}.model'.format(ii))))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "checkpoint_model = torch.load(os.path.join(savePath, '{}.model'.format(ii)))\n",
    "checkpoint_embed = torch.load(os.path.join(savePath, '{}.embed'.format(ii)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4-uFdY_l7nqN",
    "outputId": "a98b5495-842c-4c15-b4f3-db3dfd1c17c1"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "embedder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zyGcZVOrdYrz",
    "outputId": "91480fbd-6c84-494c-e37b-b195eca80575"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6DFb_gUdYr3"
   },
   "outputs": [],
   "source": [
    "loss_fxn = nn.MSELoss()\n",
    "\n",
    "# optimizer_embed = torch.optim.SGD(embedder.parameters(), lr=1e-5, momentum=0.9)\n",
    "# optimizer_model = torch.optim.SGD(model.parameters(), lr=1e-5, momentum=0.9)\n",
    "\n",
    "optimizer_embed = torch.optim.Adam(embedder.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-08)\n",
    "optimizer_model = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "lambda_embed = lambda epoch: 0.90**(epoch//10000)\n",
    "lambda_model = lambda epoch: 0.75**(epoch//10000)\n",
    "\n",
    "scheduler_embed =  torch.optim.lr_scheduler.MultiStepLR(optimizer_embed, milestones=[100000], gamma=0.1)\n",
    "scheduler_model =  torch.optim.lr_scheduler.MultiStepLR(optimizer_model, milestones=[100000], gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35yH4LL4wtJm"
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "m4cTjKgrdYr3"
   },
   "outputs": [],
   "source": [
    "# Define plotting functions\n",
    "\n",
    "def plot_pred_vs_true(eng, fcs, all_true_eng, all_true_fcs):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "#     fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "    # Energy errors figure\n",
    "    xl, xh = min(all_true_eng), max(all_true_eng)\n",
    "\n",
    "    rmse = np.sqrt(np.average((eng - all_true_eng)**2))\n",
    "    ax[0].plot(all_true_eng, eng, 'o', markersize=1, label='RMSE: {:.3f} eV/atom'.format(rmse), alpha=1)\n",
    "    ax[0].plot([xl, xh], [xl, xh], '--r')\n",
    "\n",
    "    lgnd = ax[0].legend(loc = 'upper left')\n",
    "    lgnd.legendHandles[0]._legmarker.set_markersize(6)\n",
    "    lgnd.legendHandles[0]._legmarker.set_alpha(1)\n",
    "\n",
    "    ax[0].set_xlim([xl, xh])\n",
    "    ax[0].set_ylim([xl, xh])\n",
    "\n",
    "    ax[0].set_aspect('equal')\n",
    "\n",
    "    ax[0].set_xlabel('True', fontsize=12)\n",
    "    ax[0].set_ylabel(\"Predicted\", fontsize=12)\n",
    "\n",
    "    _ = ax[0].set_title('Energies')\n",
    "    \n",
    "    # Forces errors figure\n",
    "    xl, xh = min(all_true_fcs), max(all_true_fcs)\n",
    "\n",
    "    rmse = np.sqrt(np.average((fcs - all_true_fcs)**2))\n",
    "    ax[1].plot(all_true_fcs, fcs, 'o', markersize=1, label='RMSE: {:.3f} eV/A'.format(rmse), alpha=0.05)\n",
    "    ax[1].plot([xl, xh], [xl, xh], '--r')\n",
    "\n",
    "    lgnd = ax[1].legend(loc = 'upper left')\n",
    "    lgnd.legendHandles[0]._legmarker.set_markersize(6)\n",
    "    lgnd.legendHandles[0]._legmarker.set_alpha(1)\n",
    "\n",
    "    ax[1].set_xlim([xl, xh])\n",
    "    ax[1].set_ylim([xl, xh])\n",
    "\n",
    "    ax[1].set_aspect('equal')\n",
    "\n",
    "    ax[1].set_xlabel('True', fontsize=12)\n",
    "    ax[1].set_ylabel(\"Predicted\", fontsize=12)\n",
    "\n",
    "    _ = ax[1].set_title('Forces')\n",
    "    \n",
    "#     # Forces errors figure\n",
    "#     xl, xh = min(all_true_fcs), max(all_true_fcs)\n",
    "\n",
    "#     rmse = np.sqrt(np.average((fcs - all_true_fcs)**2))\n",
    "#     ax.plot(all_true_fcs, fcs, 'o', markersize=1, label='RMSE: {:.3f} eV/A'.format(rmse), alpha=0.05)\n",
    "#     ax.plot([xl, xh], [xl, xh], '--r')\n",
    "\n",
    "#     lgnd = ax.legend(loc = 'upper left')\n",
    "#     lgnd.legendHandles[0]._legmarker.set_markersize(6)\n",
    "#     lgnd.legendHandles[0]._legmarker.set_alpha(1)\n",
    "\n",
    "#     ax.set_xlim([xl, xh])\n",
    "#     ax.set_ylim([xl, xh])\n",
    "\n",
    "#     ax.set_aspect('equal')\n",
    "\n",
    "#     ax.set_xlabel('True', fontsize=12)\n",
    "#     ax.set_ylabel(\"Predicted\", fontsize=12)\n",
    "\n",
    "#     _ = ax.set_title('Forces')\n",
    "#     plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# @@ Cell 12\n",
    "def plot_splines(splitParams, names):\n",
    "    numRows = int(max(1, np.ceil(len(splitParams)/3)))\n",
    "\n",
    "    fig, axes = plt.subplots(numRows, 3, figsize=(12, 4*numRows))\n",
    "\n",
    "    for i, (spline, name) in enumerate(zip(splitParams, names)):\n",
    "        y, bc = spline[:-2], spline[-2:]\n",
    "\n",
    "    #     if 'g' in compNames[i]:\n",
    "    #         x = np.linspace(-1, 1, len(y))\n",
    "    #     else:\n",
    "    #         x = np.linspace(2.5, 7.0, len(y))\n",
    "\n",
    "        x = np.linspace(2.5, 7.0, len(y))\n",
    "        \n",
    "        cs = CubicSpline(x, y, bc_type=((1, bc[0]), (1, bc[1])))\n",
    "        cs = CubicSpline(x, y, bc_type='natural')\n",
    "\n",
    "        plotX = np.linspace(x[0]-.1, x[-1]+.1, 100)\n",
    "        plotY = cs(plotX)\n",
    "        \n",
    "        row = i//3\n",
    "        col = i%3\n",
    "\n",
    "        if numRows > 1:\n",
    "            ax = axes[row][col]\n",
    "        else:\n",
    "            ax = axes[col]\n",
    "\n",
    "        ax.plot(x, y, 'o')\n",
    "        ax.plot(plotX, plotY)\n",
    "        ax.set_title(name)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5l_TBO4OdYr4"
   },
   "source": [
    "## Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jjc5aoxvdYr4",
    "outputId": "06b13c30-2db6-4f1f-c9f4-14c893516340",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ns = len(dataset)\n",
    "\n",
    "epochs = 1000000\n",
    "batch_size = 1024\n",
    "\n",
    "indices = np.arange(ns)\n",
    "start = time.time()\n",
    "for t in range(epochs):\n",
    "    # Build random batches\n",
    "    random.shuffle(indices)\n",
    "    batches = np.array_split(indices, ns//batch_size)\n",
    "    \n",
    "    epoch_eng = []\n",
    "    epoch_fcs = []\n",
    "    epoch_true_eng = []\n",
    "    epoch_true_fcs = []\n",
    "\n",
    "    # Evaluate all batches\n",
    "    epoch_loss = 0\n",
    "    for batch in batches:\n",
    "        batch = batch.tolist()\n",
    "        \n",
    "        for bi in badIndices:\n",
    "            if bi in batch:\n",
    "                batch.remove(bi)\n",
    "\n",
    "        if dataset.refIdx not in batch:\n",
    "            batch.append(dataset.refIdx)\n",
    "\n",
    "#         svs_eng = {\n",
    "#             'rho_A': torch.Tensor(np.vstack([dataset.svs['rho_A']['Al']['energy'][i] for i in batch])).to(device),\n",
    "#             'ffg_AA': torch.Tensor(np.vstack([dataset.svs['ffg_AA']['Al']['energy'][i] for i in batch])).to(device),\n",
    "#         }\n",
    "\n",
    "        svs_fcs = {\n",
    "            'rho_A': torch.Tensor(np.concatenate([dataset.svs['rho_A']['Al']['forces'][i] for i in batch])).to(device),\n",
    "            'ffg_AA': torch.Tensor(np.concatenate([dataset.svs['ffg_AA']['Al']['forces'][i] for i in batch])).to(device),\n",
    "        }\n",
    "\n",
    "#         all_true_eng = torch.Tensor([dataset.all_true_eng[i] for i in batch]).to(device)\n",
    "        all_true_fcs = torch.Tensor(np.concatenate([dataset.all_true_fcs[i] for i in batch])).to(device)\n",
    "        splits = [dataset.natoms[i] for i in batch]\n",
    "\n",
    "        # Compute loss\n",
    "#         descriptors_eng, descriptors_fcs = embedder.embed(svs_eng, svs_fcs)\n",
    "        descriptors_fcs = embedder.embed(svs_fcs)\n",
    "#         eng, fcs = model(descriptors_eng, descriptors_fcs, splits)\n",
    "        fcs = model(descriptors_fcs, splits)\n",
    "#         eng = eng - eng[batch.index(dataset.refIdx)]\n",
    "        \n",
    "#         epoch_eng.append(np.array(eng.cpu().detach()))\n",
    "        epoch_fcs.append(np.array(fcs.cpu().detach()))\n",
    "#         epoch_true_eng.append(np.array(all_true_eng.cpu().detach()))\n",
    "        epoch_true_fcs.append(np.array(all_true_fcs.cpu().detach()))\n",
    "\n",
    "#         loss_eng = loss_fxn(eng, all_true_eng)*10\n",
    "        loss_fcs = loss_fxn(fcs, all_true_fcs)\n",
    "\n",
    "#         loss = loss_eng + loss_fcs\n",
    "        loss = loss_fcs\n",
    "\n",
    "        # Backpropogate errors\n",
    "        optimizer_model.zero_grad()\n",
    "        optimizer_embed.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer_embed.step()\n",
    "        optimizer_model.step()\n",
    "        \n",
    "        scheduler_embed.step()\n",
    "        scheduler_model.step()\n",
    "\n",
    "        batch_loss = loss.detach().item()\n",
    "        epoch_loss += batch_loss*(len(batch)/ns)  # weighted average\n",
    "        \n",
    "#         recheck_loss = np.average(\n",
    "#             (np.array(fcs.cpu().detach()) - np.array(all_true_fcs.cpu().detach()))**2\n",
    "#         )\n",
    "        \n",
    "#         print(\"Batch loss: {:.6f} -- {:.2f} (s)\".format(batch_loss, recheck_loss))\n",
    "        \n",
    "    # Print status\n",
    "    print(\"Epoch {} loss (avg. batch loss): {:.6f} -- {:.2f} (s)\".format(t, epoch_loss, time.time()-start))\n",
    "#     break\n",
    "    model.steps += 1\n",
    "    embedder.steps += 1\n",
    "    \n",
    "    writer.add_scalar('Training loss', epoch_loss, model.steps+1)\n",
    "\n",
    "    # Log results and do garbage collection\n",
    "    if (t+1)%10 == 0:\n",
    "#         torch.save(embedder.state_dict(), os.path.join(savePath, '{}.embedder'.format(t+1)))\n",
    "#         torch.save(model.state_dict(), os.path.join(savePath, '{}.model'.format(t+1)))\n",
    "        \n",
    "        checkpoint_model = { \n",
    "            'model': model,\n",
    "            'optimizer': optimizer_model.state_dict()\n",
    "        }\n",
    "\n",
    "        checkpoint_embed = { \n",
    "            'model': embedder,\n",
    "            'optimizer': optimizer_embed.state_dict()\n",
    "        }\n",
    "\n",
    "        torch.save(checkpoint_model, os.path.join(savePath, '{}.model'.format(t+1)))\n",
    "        torch.save(checkpoint_embed, os.path.join(savePath, '{}.embed'.format(t+1)))\n",
    "        \n",
    "#         eng_np = np.array(eng.cpu().detach())\n",
    "#         fcs_np = np.array(fcs.cpu().detach())\n",
    "#         true_eng_np = np.array(all_true_eng.cpu().detach())\n",
    "#         true_fcs_np = np.array(all_true_fcs.cpu().detach())\n",
    "        \n",
    "#         eng_np = np.concatenate(epoch_eng)\n",
    "        fcs_np = np.concatenate(epoch_fcs)\n",
    "#         true_eng_np = np.concatenate(epoch_true_eng)\n",
    "        true_fcs_np = np.concatenate(epoch_true_fcs)\n",
    "        eng_np = np.zeros(1)\n",
    "        true_eng_np = np.zeros(1)\n",
    "        \n",
    "        writer.add_figure(\n",
    "            'Predictions vs. True',\n",
    "            plot_pred_vs_true(\n",
    "                eng_np,\n",
    "                fcs_np,\n",
    "                true_eng_np,\n",
    "                true_fcs_np\n",
    "            ),\n",
    "            global_step=model.steps\n",
    "        )\n",
    "        \n",
    "        splitParams = []\n",
    "        names = []\n",
    "        for k in embedder.embeddings:\n",
    "            for d in range(embedder.embeddings[k][2]):\n",
    "                for i in range(len(embedder.embeddings[k][0])):\n",
    "                    s, n = embedder._fill(k, d, i)\n",
    "                    splitParams.append(np.array(s.cpu().detach()))\n",
    "                    names.append(n)\n",
    "        \n",
    "        writer.add_figure(\n",
    "            'Splines',\n",
    "            plot_splines(splitParams, names),\n",
    "            global_step=embedder.steps\n",
    "        )\n",
    "        \n",
    "#         del descriptors_eng\n",
    "        del descriptors_fcs\n",
    "        \n",
    "#         del eng\n",
    "        del fcs\n",
    "        \n",
    "#         del loss_eng\n",
    "        del loss_fcs\n",
    "        del loss\n",
    "        \n",
    "        del eng_np\n",
    "        del fcs_np\n",
    "        del true_eng_np\n",
    "        del true_fcs_np\n",
    "        \n",
    "        del splitParams\n",
    "        \n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_model = { \n",
    "    'model': model,\n",
    "    'optimizer': optimizer_model.state_dict()\n",
    "}\n",
    "\n",
    "checkpoint_embed = { \n",
    "    'model': embed,\n",
    "    'optimizer': optimizer_embed.state_dict()\n",
    "}\n",
    "\n",
    "torch.save(checkpoint_model, os.path.join(savePath, '{}.model'.format(t+1)))\n",
    "torch.save(checkpoint_embed, os.path.join(savePath, '{}.embed'.format(t+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         del descriptors_eng\n",
    "# del descriptors_fcs\n",
    "\n",
    "# #         del eng\n",
    "# del fcs\n",
    "\n",
    "# #         del loss_eng\n",
    "# del loss_fcs\n",
    "# del loss\n",
    "\n",
    "# del eng_np\n",
    "# del fcs_np\n",
    "# del true_eng_np\n",
    "# del true_fcs_np\n",
    "\n",
    "# del splitParams\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JMWyGRsxdYsF"
   },
   "outputs": [],
   "source": [
    "# for g in optimizer_embed.param_groups:\n",
    "for ge, gm in zip(optimizer_embed.param_groups, optimizer_model.param_groups):\n",
    "    print(ge['lr'], gm['lr'])\n",
    "    ge['lr'] = 1e-4\n",
    "    gm['lr'] = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcs_np = np.concatenate(epoch_fcs)\n",
    "true_fcs_np = np.concatenate(epoch_true_fcs)\n",
    "eng_np = np.zeros(1)\n",
    "true_eng_np = np.zeros(1)\n",
    "\n",
    "plot_pred_vs_true(\n",
    "    eng_np,\n",
    "    fcs_np,\n",
    "    true_eng_np,\n",
    "    true_fcs_np\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.199**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "splitParams = []\n",
    "names = []\n",
    "for k in embedder.embeddings:\n",
    "    for d in range(embedder.embeddings[k][2]):\n",
    "        for i in range(len(embedder.embeddings[k][0])):\n",
    "            s, n = embedder._fill(k, d, i)\n",
    "            splitParams.append(np.array(s.cpu().detach()))\n",
    "            names.append(n)\n",
    "            \n",
    "plot_splines(splitParams, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "nn_with_learned_descriptors.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "191.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
